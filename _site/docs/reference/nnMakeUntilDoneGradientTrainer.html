<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
		<head>
		<meta content="en-au" http-equiv="Content-Language" />
		<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
		<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
		<title>nnMakeUntilDoneGradientTrainer</title>
		<link href='https://fonts.googleapis.com/css?family=Montserrat+Alternates:700|Varela+Round' rel='stylesheet' type='text/css'>
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
		<link rel="shortcut icon" href="/img/favicon.ico" />
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
		<link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/8.4/styles/default.min.css">
		<link rel="stylesheet" type="text/css" href="/css/style.css" />
	</head>

	<body>
		<div class="outer-wrap">
			<div id="content">
				<div class="navbar-wrap">
					<nav class="navbar ">
					  <div class="container-fluid">
					    <!-- Brand and toggle get grouped for better mobile display -->
					    <div class="navbar-header">
					      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
					        <span class="sr-only">Toggle navigation</span>
							<i class="fa fa-bars"></i>

					      </button>
					      <div class="navbar-brand" href="index.html">
					      	<p class="h1"><a href="/"><span class="nnx-nn">NN</span><span class="nnx-x">X</span></a></p>
					      	<p class="tagline"><a href="/">Neural networks for Excel</a></p>
					      </div>
					    </div>

					    <!-- Collect the nav links, forms, and other content for toggling -->
					    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
					      <ul class="nav navbar-nav">
					        <li><a href="/index.html"><i class="fa fa-home"></i>  Home</a></li>
					        <li>
								<a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"><i class="fa fa-book"></i> Docs <span class="caret"></span></a>
					          <ul class="dropdown-menu">
					            <li><a href="/docs/tutorial/">Tutorial</a></li>
					            <li><a href="/docs/reference/">Function reference</a></li>
					            <li><a href="https://github.com/ikhramts/NNX/blob/master/Samples/Iris-flower-data-set.xlsx?raw=true">
									Sample workbook
								</a></li>
					          </ul>
							</li>
					        <li><a href="https://github.com/ikhramts/nnx"><i class="fa fa-github"></i>  Source</a></li>
					      </ul>
					    </div><!-- /.navbar-collapse -->
					  </div><!-- /.container-fluid -->
					</nav>
				</div>
				<div class="content-wrap">
					<div class="container">
						<div class="row">
<div class="reference-nav col-md-3">
    <h3>Trainers</h3>
    <ul>
        <li><a href="nnMakeSimpleGradientTrainer.html">nnMakeSimpleGradientTrainer</a></li>
        <li><a href="nnMakeUntilDoneGradientTrainer.html">nnMakeUntilDoneGradientTrainer</a></li>
    </ul>

    <h3>Neural nets</h3>
    <ul>
        <li><a href="MultilayerPerceptron.html">Multilayer perceptron</a>
            <ul class="sublist">
                <li><a href="nnMakeMultilayerPerceptron.html">nnMakeMultilayerPerceptron</a></li>
                <li><a href="nnTrainMultilayerPerceptron.html">nnTrainMultilayerPerceptron</a></li>
            </ul>
        </li>
    </ul>
    
    <h3>Neural net functions</h3>
    <ul>
        <li><a href="nnFeedForward.html">nnFeedForward</a></li>
        <li><a href="nnGetWeights.html">nnGetWeights</a></li>
        <li><a href="nnMakeArray.html">nnMakeArray</a></li>
        <li><a href="nnMakeWeights.html">nnMakeWeights</a></li>
    </ul>

    <h3>Utilities</h3>
    <ul>
        <li><a href="nnClearAllObjects.html">nnClearAllObjects</a></li>
        <li><a href="nnGetCrossEntropyError.html">nnGetCrossEntropyError</a></li>
        <li><a href="nnGetMeanSquareError.html">nnGetMeanSquareError</a></li>
    </ul>
</div>
<div class="reference-body col-md-9">
    <h1>nnMakeUntilDoneGradientTrainer</h1>
    <p><code>UntilDoneGradientTrainer</code> works similarly to <a href="nnMakeSimpleGradientTrainer.html"><code>SimpleGradientTrainer</code></a>, except it splits the provided training set into a training and validation portion in proportion to <code>ValidationSetFraction</code> argument. During training, the trainer checks periodically whether the overall error on the validation set has improved, and if it has not improved after a certain number of epochs, it aborts training and sets the final neural network weights to the value that produced the best result so far.</p>
<p>This approach is designed to lower chance of overfitting compared to <code>SimpleGradientTrainer</code>, though as a tradeoff it reduces the total number of samples available for training.</p>
<h2>Inputs/outputs</h2>
<table>
<thead>
<tr>
<th>Arguments</th>
<th style="text-align:center"></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Name</code></td>
<td style="text-align:center">string, not empty</td>
<td>Name of the trainer object to create.</td>
</tr>
<tr>
<td><code>NumEpochs</code></td>
<td style="text-align:center">integer, &gt;0</td>
<td>Maximum number of backpropagation steps to perform during training. Each backpropagation step includes evaluating a batch of one or more training points.</td>
</tr>
<tr>
<td><code>LearningRate</code></td>
<td style="text-align:center">number, &gt;0</td>
<td>Used to determine the impact of gradient calculated in each backpropagation step on the neural network's weights.</td>
</tr>
<tr>
<td><code>Momentum</code></td>
<td style="text-align:center">number, ≥0</td>
<td>Used to determine the impact of gradient calculated in previous backpropagation step on the neural network's weights.</td>
</tr>
<tr>
<td><code>QuadraticRegularization</code></td>
<td style="text-align:center">number, ≥0</td>
<td>Higher values force weights to stay closer to 0, hopefully preventing overfitting.</td>
</tr>
<tr>
<td><code>BatchSize</code></td>
<td style="text-align:center">integer, &gt;0</td>
<td>Number of training samples to include in every epoch.</td>
</tr>
<tr>
<td><code>ValidationSetFraction</code></td>
<td style="text-align:center">number, strictly between 0 and 1</td>
<td>Portion of the training set to use as validation set to check whether training has improved performance of the neural network.</td>
</tr>
<tr>
<td><code>MaxEpochsWithoutImprovement</code></td>
<td style="text-align:center">integer, &gt;0</td>
<td>Training will abort after there is no error improvement on validation set after this number of backpropagation steps.</td>
</tr>
<tr>
<td><code>EpochsBetweenValidations</code></td>
<td style="text-align:center">number, &gt;0</td>
<td>Number of backpropagation steps to perform between checking for error improvement on validation set.</td>
</tr>
<tr>
<td><code>Seed</code></td>
<td style="text-align:center">integer, ≥0</td>
<td>Seed for random number generator. Training runs with the same seed and same input parameters should always produce identical results.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name of the newly created trainer object.</td>
</tr>
</tbody>
</table>
<h2>Details</h2>
<p>Given a training sample with \(N\) elements, before starting a training run, <code>UntilDoneGradientTrainer</code> selects <code>ValidationSetFraction</code>\(\cdot N\) samples to serve as validation set (randomly, without replacement).  These samples are removed from the training set and are not used for gradient calculations.  After that, the trainer proceeds with backpropagation algorithm as described in <a href="nnMakeSimpleGradientTrainer.html"><code>nnMakeSimpleGradientTrainer()</code></a>, except every <code>EpochsBetweenValidations</code> epochs it calculates the total error on the validation set.  If the trainer does not observe improvement in error after <code>MaxEpochsWithoutImprovement</code> epochs, it aborts the training run.  If not, the trainer stops after <code>NumEpochs</code> epochs.</p>
<p>Regardless of how the trainer stopped, it selects the weights that have produced lowest error on the validation set so far as the final weights for the neural network.</p>
</div>
</div>
					</div>
				</div>
			</div>
		</div>

		<div class="footer-wrap">
			<div class="footer">
				<p>Copyright 2016 Iouri Khramtsov.</p>
				<p>
					Code and binaries are licensed under <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a>,
					documentation licenced under <a href="http://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.
				</p>
			</div>
		</div>

		<script src="//cdn.jsdelivr.net/highlight.js/8.4/highlight.min.js"></script>
		<script>hljs.initHighlightingOnLoad();</script>
		<script src="https://code.jquery.com/jquery-2.2.0.min.js" crossorigin="anonymous"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
		<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({
			  TeX: { equationNumbers: { autoNumber: "AMS" } },
			  "HTML-CSS": {
			    preferredFont: "Latin-Modern",
				webFont: "Latin-Modern"
			},
			  SVG: {
				  font: "Latin-Modern"
			  }
			});
		</script>
	</body>
</html>
